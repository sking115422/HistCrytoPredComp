{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5ad5003-5334-466c-898c-66ee930874ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7d5458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating directory for final data if not already created\n",
    "\n",
    "if os.path.isdir('./data') == False:\n",
    "    os.mkdir('./data')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a759c59d-609a-4c75-b47b-78325fdf8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BTC_day_test.csv', 'BTC_day_train.csv', 'BTC_hour_test.csv', 'BTC_hour_train.csv', 'BTC_min_test.csv', 'BTC_min_train.csv', 'ETH_day_test.csv', 'ETH_day_train.csv', 'ETH_hour_test.csv', 'ETH_hour_train.csv', 'ETH_min_test.csv', 'ETH_min_train.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Getting all files names in raw_data folder and storing as list\n",
    "files = []\n",
    "for (dirpath, dirnames, filenames) in os.walk('./raw_data'):\n",
    "    files.extend(filenames)\n",
    "    break\n",
    "\n",
    "print(files)\n",
    "\n",
    "#Reading in all files in raw_data as a dataframe and storing in a list\n",
    "raw_data_list = [] \n",
    "df = pd.DataFrame()\n",
    "for each in files:\n",
    "    df = pd.read_csv('./raw_data/' + each)\n",
    "    raw_data_list.append(df)\n",
    "\n",
    "\n",
    "# tmp_list = [raw_data_list[0]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48130f12-e6fa-4450-b537-d807f905d64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inc = 0\n",
    "\n",
    "#Iterating through all dataframes in raw_data_list\n",
    "for each in raw_data_list:\n",
    "\n",
    "    dp_list = []\n",
    "    dp_list.append(None)\n",
    "    for row in range(1, each.shape[0]):\n",
    "        delta_P = each['Close'].iloc[row] - each['Close'].iloc[row - 1]\n",
    "        dp_list.append(delta_P)\n",
    "    \n",
    "    #Calculating change in price\n",
    "    each['DeltaPrice'] = dp_list\n",
    "    \n",
    "    #Min Max Scaling change in price\n",
    "    # maxDeltaPrice = max([abs(each['DeltaPrice'].max()), abs(each['DeltaPrice'].min())])\n",
    "    # each['DeltaPriceScaled'] = each['DeltaPrice']/maxDeltaPrice\n",
    "    \n",
    "    #Calulating Zscores with a 14 day moving average\n",
    "    closePriceList = each['Close'].tolist()\n",
    "    \n",
    "    std_dev_14 = []\n",
    "    for i in range(0, len(closePriceList)):\n",
    "        if (0 <= i <= 13):\n",
    "            std_dev_14.append(None)\n",
    "            continue\n",
    "        temp_list = []\n",
    "        for j in range(i - 14, i):\n",
    "            temp_list.append(closePriceList[j])\n",
    "            \n",
    "        mean = np.mean(temp_list)\n",
    "        std_dev = np.std(temp_list)\n",
    "        obs_val = closePriceList[i]\n",
    "        z = (obs_val - mean)/std_dev\n",
    "        \n",
    "        std_dev_14.append(z)\n",
    "            \n",
    "    each['Zscore'] = std_dev_14 \n",
    "    \n",
    "    # #Min Max Scaling zscores\n",
    "    # maxZscore = max([abs(each['Zscore'].max()), abs(each['Zscore'].min())])\n",
    "    # each['ZscoreScaled'] = each['Zscore']/maxZscore\n",
    "    \n",
    "    # #Min Max Scaling count\n",
    "    # maxCount = max([abs(each['Count'].max()), abs(each['Count'].min())])\n",
    "    # each['CountScaled'] = each['Count']/maxCount\n",
    "    \n",
    "    # #Min Max Scaling close\n",
    "    # maxClose = max([abs(each['Close'].max()), abs(each['Close'].min())])\n",
    "    # each['CloseScaled'] = each['Close']/maxClose\n",
    "    \n",
    "    # #Min Max Scaling Volume\n",
    "    # maxVolume = max([abs(each['Volume'].max()), abs(each['Volume'].min())])\n",
    "    # each['VolumeScaled'] = each['Volume']/maxVolume\n",
    "    \n",
    "    # #Min Max Scaling VWAP\n",
    "    # maxVWAP = max([abs(each['VWAP'].max()), abs(each['VWAP'].min())])\n",
    "    # each['VWAP_Scaled'] = each['VWAP']/maxVWAP\n",
    "    \n",
    "    #Dropping some no longer needed columns\n",
    "    each = each.drop(columns=[each.columns[0], 'timestamp', 'Asset_ID', 'Open', 'High', 'Low'])\n",
    "    \n",
    "    # #Creating Target values\n",
    "    # store = []\n",
    "    # store = each['DeltaPrice']\n",
    "    \n",
    "    # each['Target'] = store\n",
    "    # each['Target'] = each['Target'].shift(-1)\n",
    "    # each['Target'].append(None)\n",
    "    \n",
    "    \n",
    "    #Dropping first 14 rows and last rows because they contain NaN\n",
    "    each = each.drop(range(0,14))\n",
    "    # each.drop(each.tail(1).index,inplace=True)\n",
    "    \n",
    "    #Reseting dataframe index\n",
    "    each = each.reset_index(drop=True)\n",
    "    \n",
    "    # print(each)\n",
    "    \n",
    "    #Exporting all finished dataframes to cvs files in data folder\n",
    "    each.to_csv('./data/' + files[inc])\n",
    "    # each.to_csv('test.csv')\n",
    "    inc = inc + 1\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
